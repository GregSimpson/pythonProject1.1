{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# https://github.com/ismael-araujo/Testing-Libraries\n",
    "\n",
    "\n",
    "# https://towardsdatascience.com/how-to-import-all-python-libraries-with-one-line-of-code-2b9e66a5879f\n",
    "# !pip install pyforest\n",
    "# lazy_imports()\n",
    "import numpy as np\n",
    "import pyforest\n",
    "import warnings\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "# importing .csv files using Pandas\n",
    "train = pd.read_csv(\"/home/gsimpson/PycharmProjects/pythonProject1/mediumNotes/data/titanic/train.csv\")\n",
    "test = pd.read_csv(\"/home/gsimpson/PycharmProjects/pythonProject1/mediumNotes/data/titanic/test.csv\")\n",
    "\n",
    "# we need to convert the column Sex into numeric. We can easily do that with a lambda function.\n",
    "train['Sex'] = train['Sex'].apply(lambda x: 1 if x == 'male' else 2)\n",
    "\n",
    "# We can also drop a few categorical columns that we will not be used for this micro project.\n",
    "# For homework, I recommend you trying to play around with these features when you finish this article.\n",
    "train.drop(columns=[\"Name\",\"Ticket\",\"Cabin\", \"PassengerId\", \"Parch\", \"Embarked\"], inplace=True)\n",
    "#train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "df_train = DataFrame(train)\n",
    "df_train.fillna((df_train.mean().round(0)), inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "df_test = DataFrame(test)\n",
    "df_test.fillna((df_test.mean().round(0)), inplace=True)\n",
    "df_test.replace(np.nan, 'xyz', regex=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "Survived    False\nPclass      False\nSex         False\nAge         False\nSibSp       False\nFare        False\ndtype: bool"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = pd.DataFrame(df_train)\n",
    "train2.isnull().any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId    False\nPclass         False\nName           False\nSex            False\nAge            False\nSibSp          False\nParch          False\nTicket         False\nFare           False\nCabin          False\nEmbarked       False\ndtype: bool"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = pd.DataFrame(df_test)\n",
    "test2.isnull().any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "# Let's now split our train set into the variables X and y.\n",
    "# I will address all the features to X, except Survived, which is our target label.\n",
    "X = train2.drop([\"Survived\"], axis=1)\n",
    "y = train2.Survived"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# split the variable into train and test sets. I will go with the default 0.25 for the test size\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 16.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\nModel                                                                           \nLGBMClassifier                     0.82               0.81     0.81      0.82   \nLabelPropagation                   0.82               0.80     0.80      0.81   \nLabelSpreading                     0.82               0.80     0.80      0.81   \nPassiveAggressiveClassifier        0.78               0.80     0.80      0.78   \nNuSVC                              0.81               0.80     0.80      0.81   \nNearestCentroid                    0.78               0.79     0.79      0.79   \nRandomForestClassifier             0.81               0.79     0.79      0.81   \nAdaBoostClassifier                 0.80               0.79     0.79      0.80   \nSVC                                0.81               0.79     0.79      0.80   \nKNeighborsClassifier               0.80               0.78     0.78      0.80   \nXGBClassifier                      0.79               0.78     0.78      0.79   \nLogisticRegression                 0.79               0.78     0.78      0.79   \nBernoulliNB                        0.80               0.78     0.78      0.80   \nBaggingClassifier                  0.78               0.78     0.78      0.78   \nGaussianNB                         0.78               0.77     0.77      0.78   \nQuadraticDiscriminantAnalysis      0.78               0.77     0.77      0.78   \nRidgeClassifierCV                  0.78               0.77     0.77      0.78   \nRidgeClassifier                    0.78               0.77     0.77      0.78   \nCalibratedClassifierCV             0.78               0.77     0.77      0.78   \nLinearDiscriminantAnalysis         0.78               0.77     0.77      0.78   \nLinearSVC                          0.78               0.77     0.77      0.78   \nExtraTreesClassifier               0.78               0.77     0.77      0.78   \nExtraTreeClassifier                0.78               0.77     0.77      0.78   \nSGDClassifier                      0.78               0.76     0.76      0.78   \nPerceptron                         0.76               0.75     0.75      0.76   \nDecisionTreeClassifier             0.74               0.72     0.72      0.74   \nDummyClassifier                    0.51               0.49     0.49      0.51   \n\n                               Time Taken  \nModel                                      \nLGBMClassifier                       0.07  \nLabelPropagation                     0.04  \nLabelSpreading                       0.04  \nPassiveAggressiveClassifier          0.02  \nNuSVC                                0.03  \nNearestCentroid                      0.02  \nRandomForestClassifier               0.34  \nAdaBoostClassifier                   0.15  \nSVC                                  0.05  \nKNeighborsClassifier                 0.04  \nXGBClassifier                        0.10  \nLogisticRegression                   0.03  \nBernoulliNB                          0.04  \nBaggingClassifier                    0.09  \nGaussianNB                           0.03  \nQuadraticDiscriminantAnalysis        0.03  \nRidgeClassifierCV                    0.04  \nRidgeClassifier                      0.03  \nCalibratedClassifierCV               0.12  \nLinearDiscriminantAnalysis           0.02  \nLinearSVC                            0.09  \nExtraTreesClassifier                 0.16  \nExtraTreeClassifier                  0.02  \nSGDClassifier                        0.05  \nPerceptron                           0.03  \nDecisionTreeClassifier               0.04  \nDummyClassifier                      0.02  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>Balanced Accuracy</th>\n      <th>ROC AUC</th>\n      <th>F1 Score</th>\n      <th>Time Taken</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.82</td>\n      <td>0.81</td>\n      <td>0.81</td>\n      <td>0.82</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>LabelPropagation</th>\n      <td>0.82</td>\n      <td>0.80</td>\n      <td>0.80</td>\n      <td>0.81</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>LabelSpreading</th>\n      <td>0.82</td>\n      <td>0.80</td>\n      <td>0.80</td>\n      <td>0.81</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>PassiveAggressiveClassifier</th>\n      <td>0.78</td>\n      <td>0.80</td>\n      <td>0.80</td>\n      <td>0.78</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>NuSVC</th>\n      <td>0.81</td>\n      <td>0.80</td>\n      <td>0.80</td>\n      <td>0.81</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>NearestCentroid</th>\n      <td>0.78</td>\n      <td>0.79</td>\n      <td>0.79</td>\n      <td>0.79</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>RandomForestClassifier</th>\n      <td>0.81</td>\n      <td>0.79</td>\n      <td>0.79</td>\n      <td>0.81</td>\n      <td>0.34</td>\n    </tr>\n    <tr>\n      <th>AdaBoostClassifier</th>\n      <td>0.80</td>\n      <td>0.79</td>\n      <td>0.79</td>\n      <td>0.80</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>SVC</th>\n      <td>0.81</td>\n      <td>0.79</td>\n      <td>0.79</td>\n      <td>0.80</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.80</td>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.80</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>XGBClassifier</th>\n      <td>0.79</td>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.79</td>\n      <td>0.10</td>\n    </tr>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.79</td>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.79</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>BernoulliNB</th>\n      <td>0.80</td>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.80</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>BaggingClassifier</th>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.78</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>GaussianNB</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>QuadraticDiscriminantAnalysis</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifierCV</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>RidgeClassifier</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>CalibratedClassifierCV</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.12</td>\n    </tr>\n    <tr>\n      <th>LinearDiscriminantAnalysis</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.09</td>\n    </tr>\n    <tr>\n      <th>ExtraTreesClassifier</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.16</td>\n    </tr>\n    <tr>\n      <th>ExtraTreeClassifier</th>\n      <td>0.78</td>\n      <td>0.77</td>\n      <td>0.77</td>\n      <td>0.78</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.78</td>\n      <td>0.76</td>\n      <td>0.76</td>\n      <td>0.78</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>Perceptron</th>\n      <td>0.76</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.76</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>DecisionTreeClassifier</th>\n      <td>0.74</td>\n      <td>0.72</td>\n      <td>0.72</td>\n      <td>0.74</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>DummyClassifier</th>\n      <td>0.51</td>\n      <td>0.49</td>\n      <td>0.49</td>\n      <td>0.51</td>\n      <td>0.02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run some models\n",
    "#  iterate over 30 models in less than 2 seconds.\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True)\n",
    "models, predictions = clf.fit(X_train2, X_test2, y_train2, y_test2)\n",
    "models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "# check the results by running a few models and comparing them\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train2, y_train2)\n",
    "y_pred = rf.predict(X_test2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics - Random Forest:\n",
      "Accuracy: 0.7937219730941704\n",
      "F1 Score: 0.7813725490196077\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Metrics - Random Forest:')\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y_test2, y_pred)))\n",
    "print('F1 Score: ' + str(metrics.f1_score(y_test2, y_pred, average='macro')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "rf = LogisticRegression()\n",
    "rf.fit(X_train2, y_train2)\n",
    "y_pred_lr = rf.predict(X_test2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics - Logistic Regression:\n",
      "Accuracy: 0.7937219730941704\n",
      "F1 Score: 0.7813725490196077\n"
     ]
    }
   ],
   "source": [
    "print('Evaluation Metrics - Logistic Regression:')\n",
    "print('Accuracy: ' + str(metrics.accuracy_score(y_test2, y_pred)))\n",
    "print('F1 Score: ' + str(metrics.f1_score(y_test2, y_pred, average='macro')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}